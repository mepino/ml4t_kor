{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오더북 데이터: NASDAQ ITCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오더북 데이터는 마켓 참여자에 의해 생성되고 FIX 프로토콜을 따른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIX 프로토콜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "key-value pair, tag-based FIXML 구문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나스닥에서 제공하는 오더북 데이터 : TotalView-ITCH Order Book data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터에서 market depth, 주문의 주체가 되는 시장 참여자 파악 하는게 중요하다\n",
    "(나스닥에서는 순주문 불균형 지표(NOII) 만들어서 배포하기도 한다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![market depth](https://steemitimages.com/640x0/https://steemitimages.com/DQmbqCRty5i64CFeHgY6yowQmbEEKt3eYzk7M2E8fPYEVhw/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T04:35:09.947502Z",
     "start_time": "2021-02-23T04:35:09.945690Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T04:35:10.684834Z",
     "start_time": "2021-02-23T04:35:10.144768Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 압축파일 그대로 핸들링하는 용도\n",
    "import gzip\n",
    "\n",
    "#shell util : 파일 핸들링용\n",
    "import shutil\n",
    "\n",
    "# bytes 객체 변환\n",
    "from struct import unpack\n",
    "from collections import namedtuple, Counter, defaultdict\n",
    "\n",
    "# os 라이브러리 대신에 pathlib 사용해서 파일 경로를 객체로 다룸\n",
    "from pathlib import Path\n",
    "\n",
    "# 해당 url에서 파일 다운로드 받는 용도\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 축 형태 바꿔주는 용도\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T04:35:12.944751Z",
     "start_time": "2021-02-23T04:35:12.942569Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    \"\"\"Return a formatted time string 'HH:MM:SS\n",
    "    based on a numeric time() value\"\"\"\n",
    "    m, s = divmod(t, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f'{h:0>2.0f}:{m:0>2.0f}:{s:0>5.2f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NASDAQ ITCH Data from FTP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나스닥이 제공하는 binary files 가공해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name                    | Offset  | Length  | Value      | Notes                                                                                |\n",
    "|-------------------------|---------|---------|------------|--------------------------------------------------------------------------------------|\n",
    "| Message Type            | 0       | 1       | S          | System Event Message                                                                 |\n",
    "| Stock Locate            | 1       | 2       | Integer    | Always 0                                                                             |\n",
    "| Tracking Number         | 3       | 2       | Integer    | Nasdaq internal tracking number                                                      |\n",
    "| Timestamp               | 5       | 6       | Integer    | Nanoseconds since midnight                                                           |\n",
    "| Order Reference Number  | 11      | 8       | Integer    | The unique reference number assigned to the new order at the time of receipt.        |\n",
    "| Buy/Sell Indicator      | 19      | 1       | Alpha      | The type of order being added. B = Buy Order. S = Sell Order.                        |\n",
    "| Shares                  | 20      | 4       | Integer    | The total number of shares associated with the order being added to the book.        |\n",
    "| Stock                   | 24      | 8       | Alpha      | Stock symbol, right padded with spaces                                               |\n",
    "| Price                   | 32      | 4       | Price (4)  | The display price of the new order. Refer to Data Types for field processing notes.  |\n",
    "| Attribution             | 36      | 4       | Alpha      | Nasdaq Market participant identifier associated with the entered order               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set Data paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` 폴더에 `hdf` 포맷으로 저장하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T15:17:33.771126Z",
     "start_time": "2020-03-27T15:17:33.767761Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = Path('../../../data') # set to e.g. external harddrive\n",
    "itch_store = str(data_path / 'itch.h5')\n",
    "order_book_store = data_path / 'order_book.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:16:30.190820Z",
     "start_time": "2018-12-25T17:16:30.189063Z"
    }
   },
   "outputs": [],
   "source": [
    "# 종종 폴더명, 파일이름 바뀌므로 FTP 주소 들어가서 확인해야함\n",
    "FTP_URL = 'ftp://emi.nasdaq.com/ITCH/Nasdaq ITCH/'\n",
    "SOURCE_FILE = '12302019.NASDAQ_ITCH50.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:17:03.453672Z",
     "start_time": "2018-12-25T17:17:03.444627Z"
    }
   },
   "outputs": [],
   "source": [
    "def may_be_download(url):\n",
    "    \"\"\"Download & unzip ITCH data if not yet available\"\"\"\n",
    "    if not data_path.exists():\n",
    "        print('Creating directory')\n",
    "        data_path.mkdir()\n",
    "    else: \n",
    "        print('Directory exists')\n",
    "\n",
    "    filename = data_path / url.split('/')[-1]        \n",
    "    if not filename.exists():\n",
    "        print('Downloading...', url)\n",
    "        urlretrieve(url, filename)\n",
    "    else: \n",
    "        print('File exists')        \n",
    "\n",
    "    unzipped = data_path / (filename.stem + '.bin')\n",
    "    if not unzipped.exists():\n",
    "        print('Unzipping to', unzipped)\n",
    "        with gzip.open(str(filename), 'rb') as f_in:\n",
    "            with open(unzipped, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    else: \n",
    "        print('File already unpacked')\n",
    "    return unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:06:08.577453Z",
     "start_time": "2018-12-25T19:06:08.570117Z"
    },
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists\n",
      "Downloading... ftp://emi.nasdaq.com/ITCH/Nasdaq ITCH/12302019.NASDAQ_ITCH50.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22556/4015934809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmay_be_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murljoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFTP_URL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSOURCE_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22556/2932654071.py\u001b[0m in \u001b[0;36mmay_be_download\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloading...'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'File exists'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml4tz\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m                 \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml4tz\\lib\\tempfile.py\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[1;33m@\u001b[0m\u001b[0m_functools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mfunc_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m             \u001b[1;31m# Avoid closing the file as long as the wrapper is alive,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[1;31m# see issue #18879.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml4tz\\lib\\tempfile.py\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[1;33m@\u001b[0m\u001b[0m_functools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mfunc_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m             \u001b[1;31m# Avoid closing the file as long as the wrapper is alive,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[1;31m# see issue #18879.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml4tz\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_name = may_be_download(urljoin(FTP_URL, SOURCE_FILE))\n",
    "date = file_name.name.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = data_path / url.split('/')[-1]    \n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장 됐으면 여기부터 실행\n",
    "\n",
    "url = urljoin(FTP_URL, SOURCE_FILE)\n",
    "file_name = data_path / (filename.stem + '.bin')\n",
    "date = file_name.name.split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITCH Format Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### struct 모듈 써서 바이너리 데이터 핸들링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining format strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:23:09.630040Z",
     "start_time": "2018-12-25T17:23:09.628023Z"
    }
   },
   "outputs": [],
   "source": [
    "event_codes = {'O': 'Start of Messages',\n",
    "               'S': 'Start of System Hours',\n",
    "               'Q': 'Start of Market Hours',\n",
    "               'M': 'End of Market Hours',\n",
    "               'E': 'End of System Hours',\n",
    "               'C': 'End of Messages'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:23:09.841397Z",
     "start_time": "2018-12-25T17:23:09.835447Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoding = {'primary_market_maker': {'Y': 1, 'N': 0},\n",
    "            'printable'           : {'Y': 1, 'N': 0},\n",
    "            'buy_sell_indicator'  : {'B': 1, 'S': -1},\n",
    "            'cross_type'          : {'O': 0, 'C': 1, 'H': 2},\n",
    "            'imbalance_direction' : {'B': 0, 'S': 1, 'N': 0, 'O': -1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:23:09.999064Z",
     "start_time": "2018-12-25T17:23:09.992338Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "formats = {\n",
    "    ('integer', 2): 'H', # int of length 2 => format string 'H'\n",
    "    ('integer', 4): 'I',\n",
    "    ('integer', 6): '6s', # int of length 6 => parse as string, convert later\n",
    "\n",
    "    ('integer', 8): 'Q',\n",
    "    ('alpha', 1)  : 's',\n",
    "    ('alpha', 2)  : '2s',\n",
    "    ('alpha', 4)  : '4s',\n",
    "    ('alpha', 8)  : '8s',\n",
    "    ('price_4', 4): 'I',\n",
    "    ('price_8', 8): 'Q',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create message specs for binary data parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Load Message Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:19.798092Z",
     "start_time": "2018-12-25T18:36:19.783135Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "message_data = (pd.read_excel('message_types.xlsx',\n",
    "                              sheet_name='messages', engine='openpyxl')\n",
    "                .sort_values('id')\n",
    "                .drop('id', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "message_data.head( 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:18.635039Z",
     "start_time": "2018-12-25T18:36:18.630282Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# message 타입의 데이터는 message_type 행 만들어서 value 넣어줌\n",
    "\n",
    "def clean_message_types(df):\n",
    "    df.columns = [c.lower().strip() for c in df.columns]\n",
    "    df.value = df.value.str.strip()\n",
    "    df.name = (df.name\n",
    "               .str.strip() # remove whitespace\n",
    "               .str.lower()\n",
    "               .str.replace(' ', '_')\n",
    "               .str.replace('-', '_')\n",
    "               .str.replace('/', '_'))\n",
    "    df.notes = df.notes.str.strip()\n",
    "    df['message_type'] = df.loc[df.name == 'message_type', 'value']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "message_types = clean_message_types(message_data)\n",
    "message_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Get Message Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:22.741964Z",
     "start_time": "2018-12-25T18:36:22.734576Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# message 타입의 데이터는 notes 가공해서 name으로 바꿔줌\n",
    "\n",
    "message_labels = (message_types.loc[:, ['message_type', 'notes']]\n",
    "                  .dropna()\n",
    "                  .rename(columns={'notes': 'name'}))\n",
    "message_labels.name = (message_labels.name\n",
    "                       .str.lower()\n",
    "                       .str.replace('message', '')\n",
    "                       .str.replace('.', '')\n",
    "                       .str.strip().str.replace(' ', '_'))\n",
    "message_labels.to_csv('message_labels.csv', index=False)\n",
    "message_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Finalize specification details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:57.493706Z",
     "start_time": "2018-12-25T18:36:56.614416Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "message_types.message_type = message_types.message_type.ffill()\n",
    "message_types = message_types[message_types.name != 'message_type']\n",
    "message_types.value = (message_types.value\n",
    "                       .str.lower()\n",
    "                       .str.replace(' ', '_')\n",
    "                       .str.replace('(', '')\n",
    "                       .str.replace(')', ''))\n",
    "message_types.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "다시 시작할땐 저장한 message_types 파일 불러와서 쓰면 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "message_types.to_csv('message_types.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_types = pd.read_csv('message_types.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formats 딕셔너리 이용해서 value와 lenth에 따라 format 값을 넣어준다\n",
    "The parser translates the message specs into format strings and `namedtuples` that capture the message content. First, we create `(type, length)` formatting tuples from ITCH specs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:25.322056Z",
     "start_time": "2018-12-25T17:29:25.291911Z"
    }
   },
   "outputs": [],
   "source": [
    "message_types.loc[:, 'formats'] = (message_types[['value', 'length']]\n",
    "                            .apply(tuple, axis=1).map(formats))\n",
    "message_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:27.058965Z",
     "start_time": "2018-12-25T17:29:27.044699Z"
    }
   },
   "outputs": [],
   "source": [
    "# alpha 형태의 데이터만 따로 묶어보자 (format과 length)\n",
    "alpha_fields = message_types[message_types.value == 'alpha'].set_index('name')\n",
    "alpha_msgs = alpha_fields.groupby('message_type')\n",
    "alpha_formats = {k: v.to_dict() for k, v in alpha_msgs.formats}\n",
    "alpha_length = {k: v.add(5).to_dict() for k, v in alpha_msgs.length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We generate message classes as named tuples and format strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:27.755034Z",
     "start_time": "2018-12-25T17:29:27.722828Z"
    }
   },
   "outputs": [],
   "source": [
    "message_fields, fstring = {}, {}\n",
    "for t, message in message_types.groupby('message_type'):\n",
    "    message_fields[t] = namedtuple(typename=t, field_names=message.name.tolist())\n",
    "    fstring[t] = '>' + ''.join(message.formats.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alpha_fields.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_fields.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fields of `alpha` type (alphanumeric) require post-processing as defined in the `format_alpha` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:28.145192Z",
     "start_time": "2018-12-25T17:29:28.131796Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def format_alpha(mtype, data):\n",
    "    \"\"\"Process byte strings of type alpha\"\"\"\n",
    "\n",
    "    for col in alpha_formats.get(mtype).keys():\n",
    "        if mtype != 'R' and col == 'stock':\n",
    "            data = data.drop(col, axis=1)\n",
    "            continue\n",
    "        data.loc[:, col] = data.loc[:, col].str.decode(\"utf-8\").str.strip()\n",
    "        if encoding.get(col):\n",
    "            data.loc[:, col] = data.loc[:, col].map(encoding.get(col))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Process Binary Message Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The binary file for a single day contains over 350,000,000 messages worth over 12 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:45.620911Z",
     "start_time": "2018-12-25T17:29:45.606916Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def store_messages(m):\n",
    "    \"\"\"Handle occasional storing of all messages\"\"\"\n",
    "    with pd.HDFStore(itch_store) as store:\n",
    "        for mtype, data in m.items():\n",
    "            # convert to DataFrame\n",
    "            data = pd.DataFrame(data)\n",
    "\n",
    "            # parse timestamp info\n",
    "            data.timestamp = data.timestamp.apply(int.from_bytes, byteorder='big')\n",
    "            data.timestamp = pd.to_timedelta(data.timestamp)\n",
    "\n",
    "            # apply alpha formatting\n",
    "            if mtype in alpha_formats.keys():\n",
    "                data = format_alpha(mtype, data)\n",
    "\n",
    "            s = alpha_length.get(mtype)\n",
    "            if s:\n",
    "                s = {c: s.get(c) for c in data.columns}\n",
    "            dc = ['stock_locate']\n",
    "            if m == 'R':\n",
    "                dc.append('stock')\n",
    "            try:\n",
    "                store.append(mtype,\n",
    "                         data,\n",
    "                         format='t',\n",
    "                         min_itemsize=s,\n",
    "                         data_columns=dc)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(mtype)\n",
    "                print(data.info())\n",
    "                print(pd.Series(list(m.keys())).value_counts())\n",
    "                data.to_csv('data.csv', index=False)\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:45.638871Z",
     "start_time": "2018-12-25T17:29:45.623938Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "messages = defaultdict(list)\n",
    "message_count = 0\n",
    "message_type_counter = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The script appends the parsed result iteratively to a file in the fast HDF5 format using the `store_messages()` function we just defined to avoid memory constraints (see last section in chapter 2 for more on this format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code processes the binary file and produces the parsed orders stored by message type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:59:34.870288Z",
     "start_time": "2018-12-25T17:29:45.640518Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with file_name.open('rb') as data:\n",
    "    a=0\n",
    "    while a < 1000000:\n",
    "        a+=1\n",
    "\n",
    "        # determine message size in bytes\n",
    "        message_size = int.from_bytes(data.read(2), byteorder='big', signed=False)\n",
    "        \n",
    "        # get message type by reading first byte\n",
    "        message_type = data.read(1).decode('ascii')        \n",
    "        message_type_counter.update([message_type])\n",
    "\n",
    "        # read & store message\n",
    "        record = data.read(message_size - 1)\n",
    "        message = message_fields[message_type]._make(unpack(fstring[message_type], record))\n",
    "        messages[message_type].append(message)\n",
    "        \n",
    "        # deal with system events\n",
    "        if message_type == 'S':\n",
    "            seconds = int.from_bytes(message.timestamp, byteorder='big') * 1e-9\n",
    "            print('\\n', event_codes.get(message.event_code.decode('ascii'), 'Error'))\n",
    "            print(f'\\t{format_time(seconds)}\\t{message_count:12,.0f}')\n",
    "            if message.event_code.decode('ascii') == 'C':\n",
    "                store_messages(messages)\n",
    "                break\n",
    "        message_count += 1\n",
    "\n",
    "        if message_count % 2.5e7 == 0:\n",
    "            seconds = int.from_bytes(message.timestamp, byteorder='big') * 1e-9\n",
    "            d = format_time(time() - start)\n",
    "            print(f'\\t{format_time(seconds)}\\t{message_count:12,.0f}\\t{d}')\n",
    "            res = store_messages(messages)\n",
    "            if res == 1:\n",
    "                print(pd.Series(dict(message_type_counter)).sort_values())\n",
    "                break\n",
    "            messages.clear()\n",
    "\n",
    "print('Duration:', format_time(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Summarize Trading Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Trading Message Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:03.560168Z",
     "start_time": "2018-12-25T18:38:03.551636Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "counter = pd.Series(message_type_counter).to_frame('# Trades')\n",
    "counter['Message Type'] = counter.index.map(message_labels.set_index('message_type').name.to_dict())\n",
    "counter = counter[['Message Type', '# Trades']].sort_values('# Trades', ascending=False)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:05.819908Z",
     "start_time": "2018-12-25T18:38:05.810713Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(itch_store) as store:\n",
    "    store.put('summary', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Top Equities by Traded Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(itch_store) as store:\n",
    "    stocks = store['R'].loc[:, ['stock_locate', 'stock']]\n",
    "    trades = store['P'].append(store['Q'].rename(columns={'cross_price': 'price'}), sort=False).merge(stocks)\n",
    "\n",
    "trades['value'] = trades.shares.mul(trades.price)\n",
    "trades['value_share'] = trades.value.div(trades.value.sum())\n",
    "\n",
    "trade_summary = trades.groupby('stock').value_share.sum().sort_values(ascending=False)\n",
    "trade_summary.iloc[:50].plot.bar(figsize=(14, 6), color='darkblue', title='Share of Traded Value')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T15:19:06.905421Z",
     "start_time": "2020-03-27T15:19:05.149409Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(itch_store) as store:\n",
    "    stocks = store['R'].loc[:, ['stock_locate', 'stock']]\n",
    "    trades = store['P'].append(store['Q'].rename(columns={'cross_price': 'price'}), sort=False).merge(stocks)\n",
    "\n",
    "trades['value'] = trades.shares.mul(trades.price)\n",
    "trades['value_share'] = trades.value.div(trades.value.sum())\n",
    "\n",
    "trade_summary = trades.groupby('stock').value_share.sum().sort_values(ascending=False)\n",
    "trade_summary.iloc[:50].plot.bar(figsize=(14, 6), color='darkblue', title='Share of Traded Value')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
